training_linear_model_data_cattle = training_linear_model_data_cattle[complete.cases(training_linear_model_data_cattle["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_cattle$cattle.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_cattle[trainIndex,]
testData <- training_linear_model_data_cattle[-trainIndex,]
linear_model_cattle = zeroinfl(cattle.count.x ~ cattle_count_summed + surrounding_population_density + population_density + cattle.farms.x + cattle.count.y + Population..2020.census. + Area..mi.2., dist = "poisson",  data = training_linear_model_data_cattle, maxit = 1000)
stargazer(
linear_model_cattle,
type = 'text',
covariate.labels = c(
'Surrounding Cattle Count', 'Surrounding Cattle Density', 'Surrounding Population Density', "Cattle Farms", "Total State Cattle Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_cattle, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_cattle, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$cattle.count.x, train_predictions)
test_mae <- mae(testData$cattle.count.x, test_predictions)
# Print the MAE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
testing_cattle_data = linear_model_data_cattle[linear_model_data_cattle$cattle.count.x == -47, ]
predicting_cattle_data = testing_cattle_data[ , !(names(testing_cattle_data) == "cattle.count.x")]
predicting_cattle_data$cattle.count.x = predict(linear_model_cattle, newdata = predicting_cattle_data, type = "response")
# Read in csv files
linear_model_data_layer <- read.csv("../Data/linear_model_data_layer.csv")
linear_model_data_layer <- na.omit(linear_model_data_layer)
training_linear_model_data_layer <- linear_model_data_layer[linear_model_data_layer$layer.count.x != -47, ]
training_linear_model_data_layer <- training_linear_model_data_layer[complete.cases(training_linear_model_data_layer["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_layer$layer.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_layer[trainIndex, ]
testData <- training_linear_model_data_layer[-trainIndex, ]
linear_model_layer <- zeroinfl(layer.count.x ~ layer_count_summed + surrounding_population_density + population_density + layer.farm.x + layer.count.y + Population..2020.census. + Area..mi.2., dist = "poisson", data = training_linear_model_data_layer, maxit = 1000)
stargazer(
linear_model_layer,
type = 'text',
covariate.labels = c(
'Surrounding Layer Count', 'Surrounding Layer Density', 'Surrounding Population Density', "Layer Farms", "Total State Layer Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_layer, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_layer, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$layer.count.x, train_predictions)
test_mae <- mae(testData$layer.count.x, test_predictions)
# Calculate Mean Absolute Percentage Error (MAPE)
mape <- function(actual, predicted) {
# Replace zero actual values with a small constant
actual <- ifelse(actual == 0, 1e-10, actual)
mean(abs((actual - predicted) / actual)) * 100
}
train_mape <- mape(trainData$layer.count.x, train_predictions)
test_mape <- mape(testData$layer.count.x, test_predictions)
# Print the MAE and MAPE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
cat("Training MAPE:", train_mape, "%\n")
cat("Test MAPE:", test_mape, "%\n")
# Prediction for missing layer count data
testing_layer_data <- linear_model_data_layer[linear_model_data_layer$layer.count.x == -47, ]
predicting_layer_data <- testing_layer_data[, !(names(testing_layer_data) == "layer.count.x")]
predicting_layer_data$layer.count.x <- predict(linear_model_layer, newdata = predicting_layer_data, type = "response")
predicting_layer_data <- predicting_layer_data[complete.cases(predicting_layer_data["state"]), ]
predicting_layer_data
```{r}
# Load necessary libraries
library(caret)
library(pscl)
library(stargazer)
# Read in csv files
linear_model_data_sheep <- read.csv("../Data/linear_model_data_sheep.csv")
linear_model_data_sheep <- na.omit(linear_model_data_sheep)
training_linear_model_data_sheep <- linear_model_data_sheep[linear_model_data_sheep$sheep.count.x != -47, ]
training_linear_model_data_sheep <- training_linear_model_data_sheep[complete.cases(training_linear_model_data_sheep["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_sheep$sheep.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_sheep[trainIndex, ]
testData <- training_linear_model_data_sheep[-trainIndex, ]
linear_model_sheep <- zeroinfl(sheep.count.x ~  sheep_count_summed + surrounding_animal_density + population_density + sheep.farm.x + sheep.count.y + Population..2020.census. + Area..mi.2.,
dist = "poisson", data = trainData, maxit = 1000)
stargazer(
linear_model_sheep,
type = 'text',
covariate.labels = c(
'Surrounding Sheep Count', "Surrounding Sheep Density", "Surrounding Population Density", "Sheep Farms", "Total State Sheep Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_sheep, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_sheep, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$sheep.count.x, train_predictions)
test_mae <- mae(testData$sheep.count.x, test_predictions)
# Calculate Mean Absolute Percentage Error (MAPE)
mape <- function(actual, predicted) {
# Replace zero actual values with a small constant
actual <- ifelse(actual == 0, 1e-10, actual)
mean(abs((actual - predicted) / actual)) * 100
}
train_mape <- mape(trainData$sheep.count.x, train_predictions)
test_mape <- mape(testData$sheep.count.x, test_predictions)
# Print the MAE and MAPE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
cat("Training MAPE:", train_mape, "%\n")
cat("Test MAPE:", test_mape, "%\n")
# Prediction for missing sheep count data
testing_sheep_data <- linear_model_data_sheep[linear_model_data_sheep$sheep.count.x == -47, ]
predicting_sheep_data <- testing_sheep_data[, !(names(testing_sheep_data) == "sheep.count.x")]
predicting_sheep_data$sheep.count.x <- predict(linear_model_sheep, newdata = predicting_sheep_data, type = "response")
predicting_sheep_data <- predicting_sheep_data[complete.cases(predicting_sheep_data["state"]), ]
predicting_sheep_data
# Read in csv files
linear_model_data_layer <- read.csv("../Data/linear_model_data_layer.csv")
linear_model_data_layer <- na.omit(linear_model_data_layer)
training_linear_model_data_layer <- linear_model_data_layer[linear_model_data_layer$layer.count.x != -47, ]
training_linear_model_data_layer <- training_linear_model_data_layer[complete.cases(training_linear_model_data_layer["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_layer$layer.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_layer[trainIndex, ]
testData <- training_linear_model_data_layer[-trainIndex, ]
linear_model_layer <- zeroinfl(layer.count.x ~ layer_count_summed + surrounding_population_density + population_density + layer.farm.x + layer.count.y + Population..2020.census. + Area..mi.2., dist = "poisson", data = training_linear_model_data_layer, maxit = 1000)
stargazer(
linear_model_layer,
type = 'text',
covariate.labels = c(
'Surrounding Layer Count', 'Surrounding Layer Density', 'Surrounding Population Density', "Layer Farms", "Total State Layer Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_layer, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_layer, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$layer.count.x, train_predictions)
test_mae <- mae(testData$layer.count.x, test_predictions)
# Calculate Mean Absolute Percentage Error (MAPE)
mape <- function(actual, predicted) {
# Replace zero actual values with a small constant
actual <- ifelse(actual == 0, 1e-10, actual)
mean(abs((actual - predicted) / actual)) * 100
}
train_mape <- mape(trainData$layer.count.x, train_predictions)
test_mape <- mape(testData$layer.count.x, test_predictions)
# Print the MAE and MAPE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
cat("Training MAPE:", train_mape, "%\n")
cat("Test MAPE:", test_mape, "%\n")
# Create a dataframe with actual vs predicted counts for both training and test data
train_comparison <- data.frame(Actual = trainData$layer.count.x, Predicted = train_predictions, Error = abs(trainData$layer.count.x - train_predictions))
test_comparison <- data.frame(Actual = testData$layer.count.x, Predicted = test_predictions, Error = abs(testData$layer.count.x - test_predictions))
# Sort dataframes by error
train_comparison_sorted <- train_comparison[order(-train_comparison$Error), ]
test_comparison_sorted <- test_comparison[order(-test_comparison$Error), ]
# Print the sorted dataframes
print("Training Data - Actual vs Predicted (Sorted by Error):")
print(head(train_comparison_sorted, 10))
print("Test Data - Actual vs Predicted (Sorted by Error):")
print(head(test_comparison_sorted, 10))
# Prediction for missing layer count data
testing_layer_data <- linear_model_data_layer[linear_model_data_layer$layer.count.x == -47, ]
predicting_layer_data <- testing_layer_data[, !(names(testing_layer_data) == "layer.count.x")]
predicting_layer_data$layer.count.x <- predict(linear_model_layer, newdata = predicting_layer_data, type = "response")
predicting_layer_data <- predicting_layer_data[complete.cases(predicting_layer_data["state"]), ]
predicting_layer_data
# Load necessary libraries
library(caret)
library(pscl)
library(stargazer)
# Read in csv files
linear_model_data_layer <- read.csv("../Data/linear_model_data_layer.csv")
linear_model_data_layer <- na.omit(linear_model_data_layer)
training_linear_model_data_layer <- linear_model_data_layer[linear_model_data_layer$layer.count.x != -47, ]
training_linear_model_data_layer <- training_linear_model_data_layer[complete.cases(training_linear_model_data_layer["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_layer$layer.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_layer[trainIndex, ]
testData <- training_linear_model_data_layer[-trainIndex, ]
linear_model_layer <- zeroinfl(layer.count.x ~ layer_count_summed + surrounding_population_density + population_density + layer.farm.x + layer.count.y + Population..2020.census. + Area..mi.2., dist = "poisson", data = training_linear_model_data_layer, maxit = 1000)
stargazer(
linear_model_layer,
type = 'text',
covariate.labels = c(
'Surrounding Layer Count', 'Surrounding Layer Density', 'Surrounding Population Density', "Layer Farms", "Total State Layer Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_layer, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_layer, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$layer.count.x, train_predictions)
test_mae <- mae(testData$layer.count.x, test_predictions)
# Calculate Mean Absolute Percentage Error (MAPE)
mape <- function(actual, predicted) {
# Replace zero actual values with a small constant
actual <- ifelse(actual == 0, 1e-10, actual)
mean(abs((actual - predicted) / actual)) * 100
}
train_mape <- mape(trainData$layer.count.x, train_predictions)
test_mape <- mape(testData$layer.count.x, test_predictions)
# Print the MAE and MAPE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
cat("Training MAPE:", train_mape, "%\n")
cat("Test MAPE:", test_mape, "%\n")
# Create a dataframe with actual vs predicted counts and county names for both training and test data
train_comparison <- data.frame(County = trainData$county, Actual = trainData$layer.count.x, Predicted = train_predictions, Error = abs(trainData$layer.count.x - train_predictions))
knitr::opts_chunk$set(include = FALSE, message = FALSE, warning = FALSE )
library(ggplot2)
library(dplyr)
library(data.table)
library(sets)
library(stringr)
library(tidyr)
library(stargazer)
library(MASS)
library(pscl)
library(caret)
# Ensure reproducibility
set.seed(123)
usda_data = read.csv("../Data/usda_data.csv")
# Specify the values to filter (rows of state data)
values_to_filter <- c(2527, 1470, 2128, 973, 2431, 3022, 867, 767, 2039, 85, 2243, 1, 298, 2827, 1642, 1299, 1884, 674, 366, 1387, 571, 220, 161, 2206, 2364, 1094, 1215, 2966, 1821, 1585, 2926, 526, 1787, 2782, 1985, 2317, 69, 3095, 1176, 2812, 1159, 1736, 1200, 1765, 285, 1754, 294, 2311)
#Subset data between state counts and county counts
state_subset <- usda_data[usda_data$X %in% values_to_filter, ]
state_subset$state <- tolower(state_subset$state)
state_subset$state <- gsub("_", " ", state_subset$state)
county_subset <- usda_data[!(usda_data$X %in% values_to_filter), ]
county_subset$state <- tolower(county_subset$state)
county_subset$county <- tolower(county_subset$county)
county_subset$state <- gsub("_", " ", county_subset$state)
county_subset$county <- gsub("_", "", county_subset$county)
county_subset$county <- gsub("\\.", "", county_subset$county)
county_subset$county <- gsub(" ", "", county_subset$county)
county_subset$county <- gsub("'", "", county_subset$county)
#Get a list of all the US states
states <- map_data("state")
states$subregion[is.na(states$subregion)] <- "none"
#Get a list of all the US counties
counties <- map_data("county")
counties$subregion[is.na(counties$subregion)] <- "none"
counties$subregion <- gsub(" ", "", counties$subregion)
#Concatenate the counties list with the animal count data
county_subset_map <- merge(counties, county_subset, sort = FALSE, by.x = c('region', 'subregion'), by.y = c('state', 'county'))
county_subset_map <- county_subset_map[order(county_subset_map$order), ]
#Create a vector of animal names for plot
count_variables <- c("hog.count", "cattle.count", "broiler.count", "layer.count", "sheep.count")
threshold <- c(10000000, 2000000, 1.25*10^8 , 7500000, 100000)
#Loop through the different animal names to plot each animal count data
for (i in 1:length(count_variables)) {
plot_title <- gsub("\\.", " ", count_variables[i])
p <- ggplot(county_subset_map, aes(long, lat)) +
geom_polygon(aes(group = group, fill = get(count_variables[i]))) +
geom_path(data = states, aes(long, lat, group = group), color = "black") +
coord_map("albers",  lat0 = 45.5, lat1 = 29.5) +
labs(title = plot_title, fill = "Count")  +
scale_fill_gradient(name="Count")
#Make the counties red when their animal county is -47
red_counties <- county_subset_map[county_subset_map[[count_variables[i]]] == -47, ]
p <- p + geom_polygon(data = red_counties, aes(group = group), fill = "red")
print(p)
}
#Read in csv files
linear_model_data_sheep = read.csv("../Data/Animal Linear Model Data/linear_model_data_sheep.csv")
linear_model_data_sheep <- na.omit(linear_model_data_sheep)
#Separate data into known and unknown animal count values
training_linear_model_data_sheep = linear_model_data_sheep[linear_model_data_sheep$sheep.count.x != -47, ]
training_linear_model_data_sheep = training_linear_model_data_sheep[complete.cases(training_linear_model_data_sheep["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_sheep$sheep.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_sheep[trainIndex,]
testData <- training_linear_model_data_sheep[-trainIndex,]
#Create the zero inflated poisson model on the training set
linear_model_sheep = zeroinfl(sheep.count.x ~  sheep_count_summed + surrounding_animal_density + population_density + sheep.farm.x + sheep.count.y + Population..2020.census. + Area..mi.2.,  dist = "poisson",  data = trainData, maxit = 1000)
#Create a table of the regression model with each coefficient
stargazer(
linear_model_sheep,
type = 'text',
covariate.labels = c(
'Surrounding Sheep Count', "Surrounding Sheep Density", "Surrounding Population Density", "Sheep Farms", "Total State Sheep Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_sheep, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_sheep, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$sheep.count.x, train_predictions)
test_mae <- mae(testData$sheep.count.x, test_predictions)
# Print the MAE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
#Run the model on the data for which we have no animal counts
testing_sheep_data = linear_model_data_sheep[linear_model_data_sheep$sheep.count.x == -47, ]
predicting_sheep_data = testing_sheep_data[ , !(names(testing_sheep_data) == "sheep.count.x")]
predicting_sheep_data$sheep.count.x = predict(linear_model_sheep, newdata = predicting_sheep_data, type = "response")
predicting_sheep_data = predicting_sheep_data[complete.cases(predicting_sheep_data["state"]), ]
predicting_sheep_data
#Concatenate the predicted values back to the overall animal count dataset
concat = rbind(training_linear_model_data_sheep, predicting_sheep_data)
state_names = unique(concat$state)
#This for loop scales the predictions of the regression model to the state totals. Helps address any error present in the model
for (i in state_names){
#Separate the dataframe into the training and prediction set
temp_training_df = training_linear_model_data_sheep[training_linear_model_data_sheep$state == i, ]
temp_prediction_df = predicting_sheep_data[predicting_sheep_data$state == i, ]
state_count = temp_training_df$sheep.count.y[1]
#If the state count is not -47, scale the data of the counties to equal the count of the state
if (state_count != -47){
diff = state_count - sum(temp_training_df$sheep.count.x)
counties_count = sum(temp_prediction_df$sheep.count.x)
scaling_factor = diff / counties_count
predicting_sheep_data$sheep.count.x[predicting_sheep_data$state == i] =
round(predicting_sheep_data$sheep.count.x[predicting_sheep_data$state == i] * scaling_factor)
}
}
#Add the scaled data back to the total data set
concat = rbind(training_linear_model_data_sheep, predicting_sheep_data)
#Get a list of all the US counties
counties <- map_data("county")
counties$subregion[is.na(counties$subregion)] <- "none"
counties$subregion <- gsub(" ", "", counties$subregion)
#Concatenate the counties list with the animal count data
county_subset_map <- merge(counties, concat, sort = FALSE, by.x = c('region', 'subregion'), by.y = c('state', 'county.x'), all = TRUE)
county_subset_map <- county_subset_map[order(county_subset_map$order), ]
#Plot the map of the animal count data over the US
plot_title <- gsub("\\.", " ", count_variables["sheep.count.x"])
p <- ggplot(county_subset_map, aes(long, lat)) +
geom_polygon(aes(group = group, fill = get("sheep.count.x"))) +
geom_path(data = states, aes(long, lat, group = group), color = "black") +
coord_map("albers",  lat0 = 45.5, lat1 = 29.5) +
labs(title = "Sheep Count Filled", fill = "Count")
print(p)
#Read in csv files
linear_model_data_hog = read.csv("../Data/Animal Linear Model Data/linear_model_data_hog.csv")
linear_model_data_hog <- na.omit(linear_model_data_hog)
training_linear_model_data_hog = linear_model_data_hog[linear_model_data_hog$hog.count.x != -47, ]
training_linear_model_data_hog = training_linear_model_data_hog[complete.cases(training_linear_model_data_hog["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_hog$hog.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_hog[trainIndex,]
testData <- training_linear_model_data_hog[-trainIndex,]
linear_model_hog = zeroinfl(hog.count.x ~ hog_count_summed + surrounding_animal_density + population_density + hog.farm.x + hog.count.y + Population..2020.census. + Area..mi.2., dist = "poisson", data = trainData, maxit = 1000)
stargazer(
linear_model_hog,
type = 'text',
covariate.labels = c(
'Surrounding Hog Count', 'Surrounding Hog Density', 'Surrounding Population Density', "Hog Farms", "Total State Hog Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_hog, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_hog, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$hog.count.x, train_predictions)
test_mae <- mae(testData$hog.count.x, test_predictions)
# Print the MAE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
testing_hog_data = linear_model_data_hog[linear_model_data_hog$hog.count.x == -47, ]
predicting_hog_data = testing_hog_data[ , !(names(testing_hog_data) == "hog.count.x")]
predicting_hog_data$hog.count.x = predict(linear_model_hog, newdata = predicting_hog_data, type = "response")
predicting_hog_data = predicting_hog_data[complete.cases(predicting_hog_data["state"]), ]
predicting_hog_data
concat = rbind(training_linear_model_data_hog, predicting_hog_data)
state_names = unique(concat$state)
for (i in state_names){
temp_training_df = training_linear_model_data_hog[training_linear_model_data_hog$state == i, ]
temp_prediction_df = predicting_hog_data[predicting_hog_data$state == i, ]
state_count = temp_training_df$hog.count.y[1]
if (state_count != -47){
diff = state_count - sum(temp_training_df$hog.count.x)
counties_count = sum(temp_prediction_df$hog.count.x)
scaling_factor = diff / counties_count
predicting_hog_data$hog.count.x[predicting_hog_data$state == i] =
round(predicting_hog_data$hog.count.x[predicting_hog_data$state == i] * scaling_factor)
}
}
concat = rbind(training_linear_model_data_hog, predicting_hog_data)
counties <- map_data("county")
counties$subregion[is.na(counties$subregion)] <- "none"
counties$subregion <- gsub(" ", "", counties$subregion)
county_subset_map <- merge(counties, concat, sort = FALSE, by.x = c('region', 'subregion'), by.y = c('state', 'county.x'), all = TRUE)
county_subset_map <- county_subset_map[order(county_subset_map$order), ]
plot_title <- gsub("\\.", " ", count_variables["hog.count.x"])
p <- ggplot(county_subset_map, aes(long, lat)) +
geom_polygon(aes(group = group, fill = get("hog.count.x"))) +
geom_path(data = states, aes(long, lat, group = group), color = "black") +
coord_map("albers",  lat0 = 45.5, lat1 = 29.5) +
labs(title = "hog Count Filled", fill = "Count")
print(p)
#Read in csv files
linear_model_data_broiler = read.csv("../Data/Animal Linear Model Data/linear_model_data_broiler.csv")
linear_model_data_broiler <- na.omit(linear_model_data_broiler)
training_linear_model_data_broiler = linear_model_data_broiler[linear_model_data_broiler$broiler.count.x != -47, ]
training_linear_model_data_broiler = training_linear_model_data_broiler[complete.cases(training_linear_model_data_broiler["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_broiler$broiler.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_broiler[trainIndex,]
testData <- training_linear_model_data_broiler[-trainIndex,]
linear_model_broiler = zeroinfl(broiler.count.x ~ broiler_count_summed + surrounding_population_density + population_density + broiler.farm.x + broiler.count.y + Population..2020.census. + Area..mi.2.,  data = trainData,  dist = "poisson", maxit = 1000)
stargazer(
linear_model_broiler,
type = 'text',
covariate.labels = c(
'Surrounding Broiler Count', 'Surrounding Broiler Density', 'Surrounding Population Density', "Broiler Farms", "Total State Broiler Count", "County Population", "County Area"
)
)
# Predict on training and test data
train_predictions <- predict(linear_model_broiler, newdata = trainData, type = "response")
test_predictions <- predict(linear_model_broiler, newdata = testData, type = "response")
# Calculate Mean Absolute Error (MAE)
mae <- function(actual, predicted) {
mean(abs(actual - predicted))
}
train_mae <- mae(trainData$broiler.count.x, train_predictions)
test_mae <- mae(testData$broiler.count.x, test_predictions)
# Print the MAE for both training and test sets
cat("Training MAE:", train_mae, "\n")
cat("Test MAE:", test_mae, "\n")
testing_broiler_data = linear_model_data_broiler[linear_model_data_broiler$broiler.count.x == -47, ]
predicting_broiler_data = testing_broiler_data[ , !(names(testing_broiler_data) == "broiler.count.x")]
predicting_broiler_data$broiler.count.x = predict(linear_model_broiler, newdata = predicting_broiler_data, type = "response")
predicting_broiler_data = predicting_broiler_data[complete.cases(predicting_broiler_data["state"]), ]
predicting_broiler_data
concat = rbind(training_linear_model_data_broiler, predicting_broiler_data)
state_names = unique(concat$state)
for (i in state_names){
temp_training_df = training_linear_model_data_broiler[training_linear_model_data_broiler$state == i, ]
temp_prediction_df = predicting_broiler_data[predicting_broiler_data$state == i, ]
state_count = temp_training_df$broiler.count.y[1]
if (state_count != -47){
diff = state_count - sum(temp_training_df$broiler.count.x)
counties_count = sum(temp_prediction_df$broiler.count.x)
scaling_factor = diff / counties_count
predicting_broiler_data$broiler.count.x[predicting_broiler_data$state == i] =
round(predicting_broiler_data$broiler.count.x[predicting_broiler_data$state == i] * scaling_factor)
}
}
concat = rbind(training_linear_model_data_broiler, predicting_broiler_data)
counties <- map_data("county")
counties$subregion[is.na(counties$subregion)] <- "none"
counties$subregion <- gsub(" ", "", counties$subregion)
county_subset_map <- merge(counties, concat, sort = FALSE, by.x = c('region', 'subregion'), by.y = c('state', 'county.x'), all = TRUE)
county_subset_map <- county_subset_map[order(county_subset_map$order), ]
plot_title <- gsub("\\.", " ", count_variables["broiler.count.x"])
p <- ggplot(county_subset_map, aes(long, lat)) +
geom_polygon(aes(group = group, fill = get("broiler.count.x"))) +
geom_path(data = states, aes(long, lat, group = group), color = "black") +
coord_map("albers",  lat0 = 45.5, lat1 = 29.5) +
labs(title = "broiler Count Filled", fill = "Count")
print(p)
#Read in csv files
linear_model_data_layer = read.csv("../Data/Animal Linear Model Data/linear_model_data_layer.csv")
linear_model_data_layer <- na.omit(linear_model_data_layer)
training_linear_model_data_layer = linear_model_data_layer[linear_model_data_layer$layer.count.x != -47, ]
training_linear_model_data_layer = training_linear_model_data_layer[complete.cases(training_linear_model_data_layer["state"]), ]
# Define the proportion of the data to be used for training
trainIndex <- createDataPartition(training_linear_model_data_layer$layer.count.x, p = 0.8,
list = FALSE,
times = 1)
# Create the training and testing sets
trainData <- training_linear_model_data_layer[trainIndex,]
testData <- training_linear_model_data_layer[-trainIndex,]
linear_model_layer = zeroinfl(layer.count.x ~ layer_count_summed + surrounding_population_density + population_density + layer.farm.x + layer.count.y + Population..2020.census. + Area..mi.2., dist = "poisson", data = training_linear_model_data_layer, maxit = 1000)
